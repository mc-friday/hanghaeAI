{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNdJc7VtLpqwwNg6uzKU2HZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mc-friday/hanghaeAI/blob/main/7%EC%A3%BC%EC%B0%A8%5B%EC%8B%AC%ED%99%94%EA%B3%BC%EC%A0%9C%5D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets wandb peft accelerate huggingface_hub torch torchvision torchaudio evaluate trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TYrv8Xr7vYv",
        "outputId": "7c217966-3abd-4f24-e27f-a13c0ad2ff4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.5)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.11/dist-packages (0.27.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n",
            "Collecting trl\n",
            "  Downloading trl-0.14.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from trl) (13.9.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->trl) (2.18.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->trl) (0.1.2)\n",
            "Downloading trl-0.14.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.9/313.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: trl\n",
            "Successfully installed trl-0.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py \\\n",
        "    --model_name_or_path \"gpt2\" \\\n",
        "    --torch_dtype \"auto\" \\\n",
        "    --dataset_name \"wikitext\" \\\n",
        "    --dataset_config_name \"wikitext-2-raw-v1\" \\\n",
        "    --block_size 1024 \\\n",
        "    --num_workers 4 \\\n",
        "    --output_dir \"./results\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PfbdxCm7y0Y",
        "outputId": "2cf1e97c-15c3-48c8-dda7-e1ea2e5aed51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-06 19:25:27.384213: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-02-06 19:25:27.401408: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738869927.424694   49956 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738869927.431516   49956 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-06 19:25:27.454700: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmcfday\u001b[0m (\u001b[33mmcfday-apple\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/wandb/run-20250206_192531-em85va2p\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrural-bee-45\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: ⭐️ View project at \u001b[34m\u001b[4mhttps://wandb.ai/mcfday-apple/Hanghae99\u001b[0m\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: 🚀 View run at \u001b[34m\u001b[4mhttps://wandb.ai/mcfday-apple/Hanghae99/runs/em85va2p\u001b[0m\n",
            "02/06/2025 19:25:33 - INFO - root - Training/evaluation parameters TrainingArguments(\n",
            "_n_gpu=1,\n",
            "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
            "adafactor=False,\n",
            "adam_beta1=0.9,\n",
            "adam_beta2=0.999,\n",
            "adam_epsilon=1e-08,\n",
            "auto_find_batch_size=False,\n",
            "average_tokens_across_devices=False,\n",
            "batch_eval_metrics=False,\n",
            "bf16=False,\n",
            "bf16_full_eval=False,\n",
            "data_seed=None,\n",
            "dataloader_drop_last=False,\n",
            "dataloader_num_workers=0,\n",
            "dataloader_persistent_workers=False,\n",
            "dataloader_pin_memory=True,\n",
            "dataloader_prefetch_factor=None,\n",
            "ddp_backend=None,\n",
            "ddp_broadcast_buffers=None,\n",
            "ddp_bucket_cap_mb=None,\n",
            "ddp_find_unused_parameters=None,\n",
            "ddp_timeout=1800,\n",
            "debug=[],\n",
            "deepspeed=None,\n",
            "disable_tqdm=False,\n",
            "dispatch_batches=None,\n",
            "do_eval=False,\n",
            "do_predict=False,\n",
            "do_train=False,\n",
            "eval_accumulation_steps=None,\n",
            "eval_delay=0,\n",
            "eval_do_concat_batches=True,\n",
            "eval_on_start=False,\n",
            "eval_steps=None,\n",
            "eval_strategy=IntervalStrategy.NO,\n",
            "eval_use_gather_object=False,\n",
            "evaluation_strategy=None,\n",
            "fp16=False,\n",
            "fp16_backend=auto,\n",
            "fp16_full_eval=False,\n",
            "fp16_opt_level=O1,\n",
            "fsdp=[],\n",
            "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
            "fsdp_min_num_params=0,\n",
            "fsdp_transformer_layer_cls_to_wrap=None,\n",
            "full_determinism=False,\n",
            "gradient_accumulation_steps=1,\n",
            "gradient_checkpointing=False,\n",
            "gradient_checkpointing_kwargs=None,\n",
            "greater_is_better=None,\n",
            "group_by_length=False,\n",
            "half_precision_backend=auto,\n",
            "hub_always_push=False,\n",
            "hub_model_id=None,\n",
            "hub_private_repo=None,\n",
            "hub_strategy=HubStrategy.EVERY_SAVE,\n",
            "hub_token=<HUB_TOKEN>,\n",
            "ignore_data_skip=False,\n",
            "include_for_metrics=[],\n",
            "include_inputs_for_metrics=False,\n",
            "include_num_input_tokens_seen=False,\n",
            "include_tokens_per_second=False,\n",
            "jit_mode_eval=False,\n",
            "label_names=None,\n",
            "label_smoothing_factor=0.0,\n",
            "learning_rate=5e-05,\n",
            "length_column_name=length,\n",
            "load_best_model_at_end=False,\n",
            "local_rank=0,\n",
            "log_level=passive,\n",
            "log_level_replica=warning,\n",
            "log_on_each_node=True,\n",
            "logging_dir=./results/runs/Feb06_19-25-32_8264def9c097,\n",
            "logging_first_step=False,\n",
            "logging_nan_inf_filter=True,\n",
            "logging_steps=500,\n",
            "logging_strategy=IntervalStrategy.STEPS,\n",
            "lr_scheduler_kwargs={},\n",
            "lr_scheduler_type=SchedulerType.LINEAR,\n",
            "max_grad_norm=1.0,\n",
            "max_steps=-1,\n",
            "metric_for_best_model=None,\n",
            "mp_parameters=,\n",
            "neftune_noise_alpha=None,\n",
            "no_cuda=False,\n",
            "num_train_epochs=3.0,\n",
            "optim=OptimizerNames.ADAMW_TORCH,\n",
            "optim_args=None,\n",
            "optim_target_modules=None,\n",
            "output_dir=./results,\n",
            "overwrite_output_dir=False,\n",
            "past_index=-1,\n",
            "per_device_eval_batch_size=8,\n",
            "per_device_train_batch_size=8,\n",
            "prediction_loss_only=False,\n",
            "push_to_hub=False,\n",
            "push_to_hub_model_id=None,\n",
            "push_to_hub_organization=None,\n",
            "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
            "ray_scope=last,\n",
            "remove_unused_columns=True,\n",
            "report_to=['tensorboard', 'wandb'],\n",
            "restore_callback_states_from_checkpoint=False,\n",
            "resume_from_checkpoint=None,\n",
            "run_name=./results,\n",
            "save_on_each_node=False,\n",
            "save_only_model=False,\n",
            "save_safetensors=True,\n",
            "save_steps=500,\n",
            "save_strategy=SaveStrategy.STEPS,\n",
            "save_total_limit=None,\n",
            "seed=42,\n",
            "skip_memory_metrics=True,\n",
            "split_batches=None,\n",
            "tf32=None,\n",
            "torch_compile=False,\n",
            "torch_compile_backend=None,\n",
            "torch_compile_mode=None,\n",
            "torch_empty_cache_steps=None,\n",
            "torchdynamo=None,\n",
            "tpu_metrics_debug=False,\n",
            "tpu_num_cores=None,\n",
            "use_cpu=False,\n",
            "use_ipex=False,\n",
            "use_legacy_prediction_loop=False,\n",
            "use_liger_kernel=False,\n",
            "use_mps_device=False,\n",
            "warmup_ratio=0.0,\n",
            "warmup_steps=0,\n",
            "weight_decay=0.0,\n",
            ")\n",
            "[INFO|configuration_utils.py:695] 2025-02-06 19:25:33,282 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
            "[INFO|configuration_utils.py:762] 2025-02-06 19:25:33,283 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:695] 2025-02-06 19:25:33,514 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
            "[INFO|configuration_utils.py:762] 2025-02-06 19:25:33,515 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2030] 2025-02-06 19:25:33,528 >> loading file chat_template.jinja from cache at None\n",
            "[INFO|configuration_utils.py:695] 2025-02-06 19:25:33,529 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/config.json\n",
            "[INFO|configuration_utils.py:762] 2025-02-06 19:25:33,529 >> Model config GPT2Config {\n",
            "  \"_name_or_path\": \"gpt2\",\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.47.1\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:3953] 2025-02-06 19:25:33,735 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/model.safetensors\n",
            "[INFO|modeling_utils.py:4060] 2025-02-06 19:25:33,742 >> Since the `torch_dtype` attribute can't be found in model's config object, will use torch_dtype={torch_dtype} as derived from model's weights\n",
            "[INFO|modeling_utils.py:1641] 2025-02-06 19:25:33,742 >> Instantiating GPT2LMHeadModel model under default dtype torch.float32.\n",
            "[INFO|configuration_utils.py:1140] 2025-02-06 19:25:33,743 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256\n",
            "}\n",
            "\n",
            "[INFO|modeling_utils.py:4849] 2025-02-06 19:25:33,863 >> All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
            "\n",
            "[INFO|modeling_utils.py:4857] 2025-02-06 19:25:33,863 >> All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n",
            "[INFO|configuration_utils.py:1095] 2025-02-06 19:25:34,100 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--gpt2/snapshots/607a30d783dfa663caf39e06633721c8d4cfcd7e/generation_config.json\n",
            "[INFO|configuration_utils.py:1140] 2025-02-06 19:25:34,100 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"eos_token_id\": 50256\n",
            "}\n",
            "\n",
            "Using custom data configuration default-05b3762b0981b9e1\n",
            "02/06/2025 19:25:34 - INFO - datasets.builder - Using custom data configuration default-05b3762b0981b9e1\n",
            "Loading Dataset Infos from /usr/local/lib/python3.11/dist-packages/datasets/packaged_modules/json\n",
            "02/06/2025 19:25:34 - INFO - datasets.info - Loading Dataset Infos from /usr/local/lib/python3.11/dist-packages/datasets/packaged_modules/json\n",
            "Overwrite dataset info from restored data version if exists.\n",
            "02/06/2025 19:25:34 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
            "Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n",
            "02/06/2025 19:25:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n",
            "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n",
            "02/06/2025 19:25:34 - INFO - datasets.builder - Found cached dataset json (/root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n",
            "Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n",
            "02/06/2025 19:25:34 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n",
            "Caching indices mapping at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2542dfa90a6c8eaa.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Caching indices mapping at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-2542dfa90a6c8eaa.arrow\n",
            "Caching indices mapping at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e78417dd8a1b2d90.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Caching indices mapping at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-e78417dd8a1b2d90.arrow\n",
            "Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00000_of_00004.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00000_of_00004.arrow\n",
            "Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00001_of_00004.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00001_of_00004.arrow\n",
            "Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00002_of_00004.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00002_of_00004.arrow\n",
            "Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00003_of_00004.arrow\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00003_of_00004.arrow\n",
            "Spawning 4 processes\n",
            "02/06/2025 19:25:34 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
            "Map (num_proc=4):   0% 0/40 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00000_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00001_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00002_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-3ee69e59e8195ffd_00002_of_00004.arrow\n",
            "Map (num_proc=4): 100% 40/40 [00:00<00:00, 233.91 examples/s]\n",
            "Concatenating 4 shards\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
            "Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00000_of_00004.arrow\n",
            "Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00001_of_00004.arrow\n",
            "Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00002_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00002_of_00004.arrow\n",
            "Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00003_of_00004.arrow\n",
            "Spawning 4 processes\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
            "Map (num_proc=4):   0% 0/10 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00002_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00002_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00001_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00000_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-7ad1d21ddc711786_00003_of_00004.arrow\n",
            "Map (num_proc=4): 100% 10/10 [00:00<00:00, 59.05 examples/s]\n",
            "Concatenating 4 shards\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
            "Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00000_of_00004.arrow\n",
            "Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00001_of_00004.arrow\n",
            "Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00002_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00002_of_00004.arrow\n",
            "Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00003_of_00004.arrow\n",
            "Spawning 4 processes\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
            "Map (num_proc=4):   0% 0/40 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00001_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00000_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00003_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00002_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-55d1da49892849a6_00002_of_00004.arrow\n",
            "Map (num_proc=4): 100% 40/40 [00:00<00:00, 258.51 examples/s]\n",
            "Concatenating 4 shards\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
            "Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00000_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #0 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00000_of_00004.arrow\n",
            "Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00001_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #1 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00001_of_00004.arrow\n",
            "Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00002_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #2 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00002_of_00004.arrow\n",
            "Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00003_of_00004.arrow\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Process #3 will write at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00003_of_00004.arrow\n",
            "Spawning 4 processes\n",
            "02/06/2025 19:25:35 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
            "Map (num_proc=4):   0% 0/10 [00:00<?, ? examples/s]Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00000_of_00004.arrow\n",
            "02/06/2025 19:25:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00000_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00001_of_00004.arrow\n",
            "02/06/2025 19:25:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00001_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00002_of_00004.arrow\n",
            "02/06/2025 19:25:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00002_of_00004.arrow\n",
            "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00003_of_00004.arrow\n",
            "02/06/2025 19:25:36 - INFO - datasets.arrow_dataset - Caching processed dataset at /root/.cache/huggingface/datasets/json/default-05b3762b0981b9e1/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-4063e43c86e617d9_00003_of_00004.arrow\n",
            "Map (num_proc=4): 100% 10/10 [00:00<00:00, 64.00 examples/s]\n",
            "Concatenating 4 shards\n",
            "02/06/2025 19:25:36 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
            "/content/train.py:149: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `SFTTrainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = SFTTrainer(\n",
            "[INFO|training_args.py:2176] 2025-02-06 19:25:36,190 >> PyTorch: setting up devices\n",
            "/usr/local/lib/python3.11/dist-packages/trl/trainer/sft_trainer.py:359: UserWarning: You passed a dataset that is already processed (contains an `input_ids` field) together with a valid formatting function. Therefore `formatting_func` will be ignored. Either remove the `formatting_func` or pass a dataset that is not already processed.\n",
            "  warnings.warn(\n",
            "[INFO|trainer.py:2768] 2025-02-06 19:25:36,528 >> Loading model from ./results/checkpoint-2320.\n",
            "[WARNING|trainer.py:2996] 2025-02-06 19:25:36,686 >> There were missing keys in the checkpoint model loaded: ['lm_head.weight'].\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/train.py\", line 168, in <module>\n",
            "    train_result = trainer.train(resume_from_checkpoint=checkpoint)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2164, in train\n",
            "    return inner_training_loop(\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 2193, in _inner_training_loop\n",
            "    train_dataloader = self.get_train_dataloader()\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 1006, in get_train_dataloader\n",
            "    dataloader_params[\"sampler\"] = self._get_train_sampler()\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\", line 976, in _get_train_sampler\n",
            "    return RandomSampler(self.train_dataset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/data/sampler.py\", line 164, in __init__\n",
            "    raise ValueError(\n",
            "ValueError: num_samples should be a positive integer value, but got num_samples=0\n",
            "\u001b[1;34mwandb\u001b[0m: \n",
            "\u001b[1;34mwandb\u001b[0m: 🚀 View run \u001b[33mrural-bee-45\u001b[0m at: \u001b[34mhttps://wandb.ai/mcfday-apple/Hanghae99/runs/em85va2p\u001b[0m\n",
            "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250206_192531-em85va2p/logs\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b3sSm049swPq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}